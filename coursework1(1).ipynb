{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1 - Mathematics for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CID: 02232170\n",
    "\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: [20 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1:\n",
    "\n",
    "$h^*$ is a minimiser of $\\phi$ means that $\\phi(h^*) \\leq \\phi(h), \\forall h$. <br>\n",
    "\n",
    "$$\n",
    "    \\phi(h^*) + \\langle g, h'- h^* \\rangle = \\phi(h^*) + \\langle 0, h'- h^* \\rangle = \\phi(h^*) \\leq \\phi(h')\n",
    "$$\n",
    "We have proven that with $g=0$, we are able to derive the inequality in the subgradient definition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "\n",
    "Suppose that  $h^*_1$ and $h^*_2$ both minimise $\\phi$, then using 1.1.1, we know that $g = 0$ is a sub-gradient for both.<br><br>\n",
    "From the definition of $\\alpha$-strong convexity and 1.1.1 we get that\n",
    "$$\n",
    "    \\phi(h^*_1) \\geq \\phi(h^*_2) + \\alpha/2*||h^*_1 - h^*_2||^2.\n",
    "$$\n",
    "We know that $\\phi(h^*_1)$ = $\\phi(h^*_2)$ since they both minimise. Thus, \n",
    "$$\n",
    "  0 \\geq \\alpha/2*||h^*_1 - h^*_2||^2.\n",
    "$$\n",
    "Since $\\alpha$ is positive, it must be that $||h^*_1 - h^*_2|| \\leq 0$ which is only possible if $||h^*_1 - h^*_2|| = 0$, hence $h^*_1 = h^*_2$, from properties of the norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3:\n",
    "\n",
    "$\\tilde{h}$ is a minimiser of $\\phi + \\psi $ means $\\phi(\\tilde{h}) + \\psi(\\tilde{h}) \\leq \\phi(h)+ \\psi(h) , \\forall h \\in \\mathcal{H}$.<br><br>\n",
    "\n",
    "Then,\n",
    "$$\n",
    "    \\phi(\\tilde{h}) + \\psi(\\tilde{h}) \\leq \\phi(h^*)+ \\psi(h^*) \\implies  \\phi(\\tilde{h}) - \\phi(h^*) \\leq \\psi(h^*)-\\psi(\\tilde{h}) \n",
    "$$\n",
    "Using L-lipschitz of $\\psi$\n",
    "$$\n",
    "    \\phi(\\tilde{h}) - \\phi(h^*) \\leq \\psi(h^*)- \\psi(\\tilde{h})  \\leq L||h^*-\\tilde{h}||. \n",
    "$$\n",
    "Using $\\alpha$-strong convexity of $\\phi$ and using 1.1.1 (0 is a sub gradient of $h^*$)\n",
    "$$\n",
    "  \\phi(\\~{h}) \\geq \\phi(h) + \\langle 0, \\~{h}- h^* \\rangle + \\frac{\\alpha}{2}||h^*-\\tilde{h}||^2 \\implies   \\phi(\\~{h}) -  \\phi(h) \\geq \\frac{\\alpha}{2}||h^*-\\tilde{h}||^2 \n",
    "\n",
    "$$\n",
    "Combining the two inequalities above and below $\\phi(\\tilde{h}) - \\phi(h^*)$ \n",
    "$$\n",
    "    \\frac{\\alpha}{2}||h^*-\\tilde{h}||^2 \\leq L||h^*-\\tilde{h}||. \\implies ||h^*-\\tilde{h}|| \\leq \\frac{2L}{\\alpha}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1:\n",
    "We can define an $f$ as follows:<br>\n",
    "$$\n",
    " f(h) = \\frac{1}{n} \\left( \\ell(h, z_i) - \\ell(h, z_i') \\right) \\\\\n",
    "$$\n",
    "$$\n",
    "f(h) - f(h') = \\frac{1}{n} \\left( \\left( \\ell(h, z_i) - \\ell(h, z_i') \\right) -  \\left( \\ell(h', z_i) - \\ell(h', z_i') \\right) \\right) \\\\\n",
    "\\left| f(h) - f(h') \\right| \\leq \\frac{1}{n} \\left| \\ell(h, z_i) - \\ell(h', z_i) \\right| + \\left| \\ell(h, z_i') - \\ell(h', z_i') \\right| \\\\\n",
    "$$\n",
    "Using that $g_{z_i}(h) = \\ell(h, z_i)$ is $L$-Lipschitz for any $z_i$, we have:\n",
    "$$\n",
    "\\left| f(h) - f(h') \\right| \\leq \\frac{1}{n} \\left( \\sum_{i=1}^n \\left| g_{z_i}(h) - g_{z_i}(h') \\right| + \\left| g_{z_i}(h) - g_{z_i}(h') \\right| \\right) \\\\\n",
    "\\leq \\frac{1}{n} \\left( (L + L) \\|h - h'\\| \\right) = \\frac{2L}{n} \\|h - h'\\| \n",
    "$$\n",
    "hence, the Lipschitz constant of $f$ is $\\frac{2L}{n}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "##### Preliminary Proofs:\n",
    "\"The sum of $\\alpha$-strongly convex functions is $\\alpha$-strongly convex.\"<br><br>\n",
    "Proof:<br>\n",
    "Let $\\phi_1$ and $\\phi_2$ be $\\alpha$-strongly convex and $\\beta$-strongly convex functions. Then, for any $h, h' \\in \\mathcal{H}$ and $t \\in [0,1]$, we have:\n",
    "$$\n",
    "\\phi_1(th + (1-t)h') \\leq t\\phi_1(h) + (1-t)\\phi_1(h') - \\frac{\\alpha}{2}t(1-t)||h-h'||^2\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\phi_2(th + (1-t)h') \\leq t\\phi_2(h) + (1-t)\\phi_2(h') - \\frac{\\beta}{2}t(1-t)||h-h'||^2\n",
    "$$\n",
    "Adding these two inequalities together, we get:\n",
    "$$\n",
    "\\phi_1(th + (1-t)h') + \\phi_2(th + (1-t)h') \\leq t(\\phi_1(h) + \\phi_2(h)) + (1-t)(\\phi_1(h') + \\phi_2(h')) - \\frac{(\\alpha+ \\beta)}{2} t(1-t)||h-h'||^2\n",
    "$$\n",
    "This shows that $\\phi_1 + \\phi_2$ is also $\\\\alpha+\\beta/2$-strongly convex.\n",
    "Hence, by induction, the sum of $n$ $\\alpha$-strongly convex functions is $\\alpha$-strongly convex. For different $\\alpha_i$ for each function, the sum is $(\\sum_{i=1}^{n} \\alpha_i)$-strongly convex.<br><br>\n",
    "\n",
    "Also, note that $c\\phi$ is $\\alpha c$-strongly convex for any $\\alpha$-strongly convex function $\\phi$ and $c > 0$. This follows directly from the usual definition of strong convexity.\n",
    "\n",
    "##### Proof:\n",
    "\n",
    "Using the Lipschitz property of $\\ell$, we have: \n",
    "$$\n",
    "| \\ell(\\hat{h}, z) - \\ell(\\hat{h^{(i)}}, z) | \\leq L ||\\hat{h}- \\hat{h^{(i)}}||\n",
    "$$\n",
    "Now, we would like to bound $||\\hat{h}- \\hat{h^{(i)}}||$.\n",
    "Note that both $\\hat{h}$ and $\\hat{h^{(i)}}$ are minimisers of their respective functions. <br>\n",
    "Define:\n",
    "$$\n",
    "    \\phi(h) = \\frac{1}{n} \\sum_{z_i \\in S}^{n} \\ell(h, z_i)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "    \\phi_{S^{(i)}}(h) = \\frac{1}{n} \\sum_{z_i \\in S^{(i)}} \\ell(h, z_i)\n",
    "$$\n",
    "where $S^{(i)}$ is the dataset $S$ with $z_i$ replaced by $z_i'$.<br>\n",
    "Both $\\phi$ and $\\phi_{S^{(i)}}$ are $\\alpha$-strongly convex as they are sums of $\\frac{1}{n}$-scaled $\\alpha$-strongly convex functions (from the preliminary proof).<br>\n",
    "Now, using the definition of $\\hat{h}$ and $\\hat{h_n^{(i)}}$ as minimisers and $\\alpha$-strong convexity, we have:\n",
    "$$\n",
    "    \\phi(\\hat{h^{(i)}}) \\geq \\phi(\\hat(h)) +\\frac{\\alpha}{2}||\\hat{h}- \\hat{h^{(i)}}||^2 \\implies \\phi(\\hat{h^{(i)}}) - \\phi(\\hat{h}) \\geq \\frac{\\alpha}{2}||\\hat{h}- \\hat{h^{(i)}}||^2\n",
    "$$\n",
    "Similarly,\n",
    "$$\n",
    "    \\phi_{S^{(i)}}(\\hat{h}) \\geq \\phi_{S^{(i)}}(\\hat{h^{(i)}}) +\\frac{\\alpha}{2}||\\hat{h}- \\hat{h^{(i)}}||^2 \\implies \\phi_{S^{(i)}}(\\hat{h}) - \\phi_{S^{(i)}}(\\hat{h^{(i)}}) \\geq \\frac{\\alpha}{2}||\\hat{h}- \\hat{h^{(i)}}||^2\n",
    "$$\n",
    "Adding these two inequalities, we get:\n",
    "$$\n",
    "    \\phi(\\hat{h^{(i)}}) - \\phi(\\hat{h}) + \\phi_{S^{(i)}}(\\hat{h}) - \\phi_{S^{(i)}}(\\hat{h^{(i)}}) \n",
    "    \\geq \\alpha ||\\hat{h}- \\hat{h^{(i)}}||^2\n",
    "$$\n",
    "This equivalent to only considering the terms with $z_i$ and $z_i'$ as all other terms cancel out:\n",
    "$$\n",
    "  \\frac{1}{n} (\\ell(\\hat{h^{(i)}}, z_i) - \\ell(\\hat{h}, z_i) + \\ell(\\hat{h}, z_i) - \\ell(\\hat{h^{(i)}}, z_i')) \n",
    "  \\geq \\alpha ||\\hat{h}- \\hat{h^{(i)}}||^2\n",
    "$$\n",
    "We know that $\\ell$ is L-Lipschitz and from 1.2.1 so using the absolute value to bound the left hand side, we have:\n",
    "$$\n",
    "  \\frac{1}{n} (|\\ell(\\hat{h^{(i)}}, z_i) - \\ell(\\hat{h}, z_i)| + |\\ell(\\hat{h}, z_i) - \\ell(\\hat{h^{(i)}}, z_i')|) \\leq \\frac{L}{n} ||\\hat{h^{(i)}} - \\hat{h}|| + \\frac{L}{n} ||\\hat{h^{(i)}} - \\hat{h}|| = \\frac{2L}{n} ||\\hat{h^{(i)}} - \\hat{h}||\n",
    "$$\n",
    "$$\n",
    "\\alpha ||\\hat{h}- \\hat{h^{(i)}}||^2 \\leq  \\frac{2L}{n} ||\\hat{h^{(i)}} - \\hat{h}|| \\implies ||\\hat{h}- \\hat{h^{(i)}}|| \\leq \\frac{2L}{\\alpha n}\n",
    "$$\n",
    "Using this bound in the Lipschitz inequality at the start, we have:\n",
    "$$\n",
    "| \\ell(\\hat{h}, z) - \\ell(\\hat{h^{(i)}}, z) | \\leq L ||\\hat{h}- \\hat{h^{(i)}}|| \\leq L * \\frac{2L}{\\alpha n} = \\frac{2L^2}{\\alpha n}\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_S[R(\\hat{h}) - \\hat{R}_S(\\hat{h})] =  \\mathbb{E}_S[R(\\hat{h})] - \\mathbb{E}_S[\\hat{R}_S(\\hat{h})]\\tag{linearity of Expectation}\n",
    "$$\n",
    "$$\n",
    "= \\mathbb{E}_S[\\mathbb{E}_z[\\ell(\\hat{h}, z)]] - \\mathbb{E}_S[\\frac{1}{n}\\Sigma_{i=1}^{n} \\ell(\\hat{h}, z_i)] \n",
    "$$\n",
    "$$\n",
    "= \\mathbb{E}_{S,z}[\\ell(\\hat{h}, z)] - \\frac{1}{n}\\Sigma_{i=1}^{n}\\mathbb{E}_S[ \\ell(\\hat{h}, z_i)] \\tag{Fubini's Theorem (1)}\n",
    "$$\n",
    "\n",
    "Focusing on the second term, we will introduce a $z$: $$ \\mathbb{E}_{S,z}[\\ell(\\hat{h}, z_i)] $$ We can argue that it is equivalent to: \n",
    "$$ \n",
    "\\mathbb{E}_{S,z}[\\ell(\\hat{h}, z_i)] \n",
    "$$ \n",
    "each $z_i$ is drawn i.i.d from the same distribution as $z$, hence we can replace one of the $z_i$ with $z$ without changing the expectation. You can think of the expectations as integrals across $ z_1,..,z_n$ and can introduce z as a new element in a new sample. then move the $\\int_z$ to the inside and remove the integral that is outside now. The new $\\hat{h}^{(i)}$ will be training across $z_1,..,z_{i-1},z,z_{i+1},..,z_n$ where we have lost $z_i$ for $z$. Hence, we have:\n",
    "$$\n",
    "\\mathbb{E}_{S,z}[ \\ell(\\hat{h}, z_i)] = \\mathbb{E}_{S,z}[\\ell(\\hat{h^{(i)}}, z)] \n",
    "$$\n",
    "Substituting this back into the original equation, we have:\n",
    "$$\n",
    "\\mathbb{E}_S[R(\\hat{h}) - \\hat{R}_S(\\hat{h})] = \\mathbb{E}_{S,z}[\\ell(\\hat{h}, z)] - \\frac{1}{n}\\Sigma_{i=1}^{n}\\mathbb{E}_{S,z}[\\ell(\\hat{h^{(i)}}, z)] \n",
    "$$\n",
    "Now lets try find a bound for this:\n",
    "$$\n",
    "|\\mathbb{E}_S[R(\\hat{h}) - \\hat{R}_S(\\hat{h})] | = |\\mathbb{E}_{S,z}[\\ell(\\hat{h}, z)] - \\frac{1}{n}\\Sigma_{i=1}^{n}\\mathbb{E}_{S,z}[\\ell(\\hat{h^{(i)}}, z)] |\\\\\n",
    "= |\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{S,z}[\\ell(\\hat{h}, z)] - \\mathbb{E}_{S,z}[\\ell(\\hat{h^{(i)}}, z)] | = |\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{S,z}[\\ell(\\hat{h}, z) - \\ell(\\hat{h^{(i)}}, z)] | \\\\\n",
    "\\leq \\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{S,z}[|\\ell(\\hat{h}, z) - \\ell(\\hat{h^{(i)}}, z)|] \\leq \\frac{1}{n}\\sum_{i=1}^{n}\\frac{2L^2}{\\alpha n} = \\frac{2L^2}{\\alpha n}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4:\n",
    "\n",
    "Since H is closed, we can say that the infimum is attained within H. Thus, $R^*_H= inf_{h \\in H} R(h) = \\min_{h \\in H} R(h) = R(h^*) $ where h* is the minimiser of R in H. <br>\n",
    "Then, we have:\n",
    "$$\n",
    "\\mathbb{E}_S[R(\\hat{h}) - R_\\mathcal{H}^*] = \\mathbb{E}_S[R(\\hat{h}) - \\hat{R}_S(\\hat{h}) + \\hat{R}_S(\\hat{h}) - R_\\mathcal{H}^*]\\\\\n",
    " = \\mathbb{E}_S[R(\\hat{h}) - \\hat{R}_S(\\hat{h})] + \\mathbb{E}_S[\\hat{R}_S(\\hat{h}) - R(h^*)]\n",
    "$$\n",
    "Focussing on the second term\n",
    "$$\n",
    "\\mathbb{E}_S[\\hat{R}_S(\\hat{h}) - R(h^*)] = \\mathbb{E}_S[\\hat{R}_S(\\hat{h})] - R(h^*) = \\mathbb{E}_S[\\hat{R}_S(\\hat{h})] - \\mathbb{E}_S[\\hat{R}_S(h^*)] = E_S[\\hat{R}_S(\\hat{h}) - \\hat{R}_S(h^*)]\n",
    "$$\n",
    "$\\hat{h}$ minimises $\\hat{R}_S(h)$, hence $\\hat{R}_S(\\hat{h}) \\leq \\hat{R}_S(h^*)$ and thus $\\mathbb{E}_S[\\hat{R}_S(\\hat{h}) - \\hat{R}_S(h^*)] \\leq 0$.<br>\n",
    "\n",
    "Thus, we have:\n",
    "$$\n",
    "\\mathbb{E}_S[R(\\hat{h}) - \\hat{R}_S(\\hat{h})] + \\mathbb{E}_S[\\hat{R}_S(\\hat{h}) - R(h^*)] \\leq \\frac{2L^2}{\\alpha n} + 0 = \\frac{2L^2}{\\alpha n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5:\n",
    "\n",
    "We want to provide a $1-\\delta$ bound for $R(\\hat{h}_n) - R^*_H$. In other words, $ P(R(\\hat{h}_n) - R^*_H \\leq K) \\geq 1-\\delta$<br>\n",
    "Define $f(S) = R(\\hat{h}) - R_H^*$ . hence \n",
    "$$\n",
    "|f(S) - f(S^{i})| = |(R(\\hat{h}) - R_H^*) - (R(\\hat{h}^{(i)}) - R_H^*)| = |R(\\hat{h}) - R(\\hat{h}^{(i)})|\\\\ = |\\mathbb{E}_z(\\ell(\\hat{h},z) - \\ell(\\hat{h}^{(i)}, z))| \\leq \\mathbb{E}_z|\\ell(\\hat{h},z) - \\ell(\\hat{h}^{(i)}, z)| \\leq \\frac{2L^2}{\\alpha n}\n",
    "$$ <br>\n",
    "Matching this to McDiarmid's inequality, we are setting $c_i = \\frac{2L^2}{\\alpha n}$ for all i. Hence, $\\Sigma_{i=1}^{n} c_i^2 = n * (\\frac{2L^2}{\\alpha n})^2 = \\frac{4L^4}{\\alpha^2 n}$.<br>\n",
    "Using McDiarmid's inequality, we have an expression for $\\delta$ in terms of $\\epsilon$ and $c_i$:\n",
    "$$\n",
    "    \\mathbb{P}[f(S) - \\mathbb{E}_S[f(S)] \\geq \\epsilon] \\leq \\exp(\\frac{-2\\epsilon^2}{\\sum_i^n c_i^2})\\\\\n",
    "    \\implies \\delta = \\exp(\\frac{-2\\epsilon^2}{\\sum_i^n c_i^2}) \\implies \\log(\\delta) = \\frac{-2\\epsilon^2}{\\sum_i^n c_i^2} \\implies \\epsilon = \\frac{L^2}{\\alpha}\\sqrt{\\frac{2\\log(\\delta^{-1})}{n}}\n",
    "$$\n",
    "$$\\mathbb{E}_S[f(S)] = \\mathbb{E}_S[R(\\hat{h}) - R_H^*] \\leq \\frac{2L^2}{\\alpha n}\\tag{from Question 4}$$\n",
    "Thus, we have:\n",
    "$$\n",
    "\\mathbb{P}[R(\\hat{h}) - R_H^* \\leq \\frac{2L^2}{\\alpha n} + \\frac{L^2}{\\alpha}\\sqrt{\\frac{2\\log(\\delta^{-1})}{n}}] \\geq 1 - \\delta\n",
    "$$\n",
    "By subbing in $f(S) = R(\\hat{h}) - R_H^*$, using the bound from question 4 and rearranging to get  $1 - \\delta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "Define $\\phi_z(h) = \\ell(h,z) + \\frac{\\lambda}{2}||h||^2$\n",
    "Aim: Show that $\\phi_z$ is strongly convex and find its constant.<br>\n",
    "i.e $\\phi_z(th + (1-t)h') \\leq t\\phi_z(h) + (1-t)\\phi_z(h') - \\frac{\\alpha}{2}t(1-t)||h-h'||^2$ for some $\\alpha > 0$. Where $t \\in [0,1]$.\n",
    "Substituting $\\phi_z$,\n",
    "$$\n",
    "    \\ell(th + (1-t)h',z) + \\frac{\\lambda}{2}||th + (1-t)h'||^2 \\leq t\\ell(h,z) + (1-t)\\ell(h',z) + \\frac{\\lambda}{2}(t||h||^2 + (1-t)||h'||^2) - \\frac{\\alpha}{2}t(1-t)||h-h'||^2\n",
    "$$\n",
    "Isolating the term with $\\alpha$, we want to bound the left hand side in the same format as the right hand side:\n",
    "$$\n",
    "    \\ell(th + (1-t)h',z) + \\frac{\\lambda}{2}||th + (1-t)h'||^2 - t\\ell(h,z) - (1-t)\\ell(h',z) - \\frac{\\lambda}{2}(t||h||^2 + (1-t)||h'||^2) \\leq - \\frac{\\alpha}{2}t(1-t)||h-h'||^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ell(th + (1-t)h',z) + \\frac{\\lambda}{2}||th + (1-t)h'||^2 - t\\ell(h,z) - (1-t)\\ell(h',z) - \\frac{\\lambda}{2}(t||h||^2 + (1-t)||h'||^2)\\\\\n",
    "\\leq \\frac{\\lambda}{2}||th + (1-t)h'||^2 - \\frac{\\lambda}{2}(t||h||^2 + (1-t)||h'||^2) \\\\\n",
    "\\text{(since $\\ell$ is convex)} \\\\\n",
    " = \\frac{\\lambda}{2} (||th + (1-t)h'||^2 - t||h||^2 - (1-t)||h'||^2) \\\\\n",
    " \\text{(expanding norms with inner product)} \\\\\n",
    "\n",
    " = \\frac{\\lambda}{2} (t^2||h||^2 + 2t(1-t)\\langle h, h' \\rangle + (1-t)^2||h'||^2 - t||h||^2 - (1-t)||h'||^2) \\\\\n",
    " = \\frac{\\lambda}{2} ( -t(1-t)(||h||^2 - 2\\langle h, h' \\rangle + ||h'||^2)) \\\\\n",
    " = \\frac{\\lambda}{2} ( -t(1-t)||h-h'||^2) \\\\\n",
    "$$\n",
    "We're we collected like terms and factorised out -t(1-t).<br>\n",
    "Thus, we have:\n",
    "$$\n",
    "    \\ell(th + (1-t)h',z) + \\frac{\\lambda}{2}||th + (1-t)h'||^2 - t\\ell(h,z) - (1-t)\\ell(h',z) - \\frac{\\lambda}{2}(t||h||^2 + (1-t)||h'||^2) \\leq - \\frac{\\lambda}{2}t(1-t)||h-h'||^2\n",
    "$$\n",
    "Hence, $\\phi_z$ is $\\lambda$-strongly convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "Using the same defintition of $\\phi_z$, we can show that it is also Lipschitz.<br>\n",
    "Aim: Show that $|\\phi_z(h) - \\phi_z(h')| \\leq L'||h-h'||$ for some $L' > 0$.<br>\n",
    "Substituting $\\phi_z$,\n",
    "$$\n",
    "    |\\phi_z(h) - \\phi_z(h')| = |\\ell(h,z) + \\frac{\\lambda}{2}||h||^2 - \\ell(h',z) - \\frac{\\lambda}{2}||h'||^2| \\\\\n",
    "    \\leq |\\ell(h,z) - \\ell(h',z)| + \\frac{\\lambda}{2} | ||h||^2 - ||h'||^2 | \\\\\n",
    "    \\leq L||h-h'|| + \\frac{\\lambda}{2} | ||h||^2 - ||h'||^2 | = L||h-h'||^2 + \\frac{\\lambda}{2}| (||h|| + ||h'||)(||h|| - ||h'||) | \\\\\n",
    "    \\leq L||h-h'|| + \\frac{\\lambda}{2}(||h|| + ||h'||)||h-h'|| \\\\\n",
    "    \\leq L||h-h'|| + \\frac{\\lambda}{2}(B + B)||h-h'|| \\\\\n",
    "    = (L + \\lambda B)||h-h'||\n",
    "    \n",
    "$$\n",
    "We used the cauchy-schwarz and then reverse triangle inequality above. Hence, $\\phi_z$ is Lipschitz with constant $L + \\lambda B$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3:\n",
    "Idea: Define a new Loss function for which we can define a new risk function and then use the results from part 2 to get the bound.<br>\n",
    "Define a new loss function using our $\\phi_z$ from before:\n",
    "$$\n",
    "   \\ell'(h,z) = \\phi_z(h, z) = \\ell(h,z) + \\frac{\\lambda}{2}||h||^2\n",
    "$$\n",
    "Then our empirical risk function is:\n",
    "$$\n",
    "    \\hat{R}'_S(h) = \\frac{1}{n} \\sum_{i=1}^{n} \\ell'(h, z_i) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\ell(h,z_i) + \\frac{\\lambda}{2}||h||^2 \\right) = \\hat{R}_S(h) + \\frac{\\lambda}{2}||h||^2\n",
    "$$\n",
    "Our new risk function is: \n",
    "$$\n",
    "R'(h) = \\mathbb{E}_z[\\ell'(h,z)] = \\mathbb{E}_z[\\ell(h,z) + \\frac{\\lambda}{2}||h||^2] = R(h) + \\frac{\\lambda}{2}||h||^2\n",
    "$$\n",
    "Our new infimum value is:\n",
    "$$\n",
    "R^*_{H,\\lambda} = inf(R'(h)) = inf ({R(h) + \\frac{\\lambda}{2}||h||^2 | }) \\text{, for h in H}\n",
    "$$\n",
    "Note that ${\\hat{h}_\\lambda}$ minimises $\\hat{R}'_S(h)$. Using 1.2.5, since our new loss function is lipschitz and strongly convex (from 1.3.1 and 1.3.2), we want something of the form:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}[R(\\hat{h}) - R_H^* \\leq \\frac{2L^2}{\\alpha n} + \\frac{L^2}{\\alpha}\\sqrt{\\frac{2\\log(\\delta^{-1})}{n}}] \\geq 1 - \\delta\n",
    "$$\n",
    "And with our lipschitz and strong convex constants from before, we have:\n",
    "$$\n",
    "\\mathbb{P}[R'(\\hat{h}_\\lambda) - R^*_{H,\\lambda} \\leq \\frac{2(L + \\lambda B)^2}{\\lambda n} + \\frac{(L + \\lambda B)^2}{\\lambda}\\sqrt{\\frac{2\\log(\\delta^{-1})}{n}}] \\geq 1 - \\delta \\\\\n",
    "\\implies \\mathbb{P}[R'(\\hat{h}_\\lambda) - R^*_{H,\\lambda} \\leq \\frac{(L + \\lambda B)^2}{\\lambda}(\\frac{2}{n} + \\sqrt{\\frac{2\\log(\\delta^{-1})}{n}})] \\geq 1 - \\delta\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4:\n",
    "\n",
    "We just need to minimise\n",
    "$$ f(\\lambda) = \\frac{(L + \\lambda B)^2}{\\lambda} $$\n",
    " wrt. $\\lambda$ since the other terms do not depend on $\\lambda$.<br>\n",
    "Taking the derivative wrt. $\\lambda$ and setting to 0:\n",
    "$$\n",
    "f'(\\lambda) = \\frac{2B(L + \\lambda B)}{\\lambda} - \\frac{(L + \\lambda B)^2}{\\lambda^2} = 0 \\\\ . \\\\\n",
    "\\implies \\frac{L + \\lambda B}{\\lambda}[2B - \\frac{(L + \\lambda B)}{\\lambda}] = 0 \\\\\n",
    "$$\n",
    "So either $L + \\lambda B = 0$ which is not possible since $\\lambda > 0$ or $\\lambda = \\frac{L}{B}$.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "***\n",
    "\n",
    "## Exercise 2: [15 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Since $\\nabla f$ is L-Lipschitz, we have: $ \\||\\nabla f(x) - \\nabla f(y)\\||_{2} \\leq L \\||x - y\\||_{2} $.\n",
    "Let's also define $\\Phi(t) = f(x-td)$ such that $ \\Phi'(t) = \\nabla f(x-td)^T (-d) = \\langle -\\nabla f(x-td), d \\rangle $\n",
    ". Using the Fundamental Theorem of Calculus, we have:\n",
    "$$\n",
    "f(x - d) - f(x) = \\Phi(1) - \\Phi(0) = \\int_{0}^{1} \\Phi'(t) ds = \\int_{0}^{1} \\langle  -\\nabla f(x-td), d \\rangle ds\n",
    "$$\n",
    "adding and subtracting $\\nabla f(x)$ inside the inner product, we get:\n",
    "$$\n",
    " = \\int_{0}^{1} \\langle  -\\nabla f(x), d \\rangle ds + \\int_{0}^{1} \\langle  \\nabla f(x) - \\nabla f(x-td), d \\rangle ds\n",
    "$$\n",
    "Using Cauchy-Schwarz inequality on the second term, we have:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\n",
    "\\leq \\langle - \\nabla f(x), d \\rangle + \\int_{0}^{1} \\||\\nabla f(x) - \\nabla f(x-td)\\||_{2} \\||d\\||_{2} ds\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "Using the L-Lipschitz property of $\\nabla f$, we have:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\n",
    "\\leq \\langle - \\nabla f(x), d \\rangle + \\int_{0}^{1} L \\||td\\||_{2} \\||d\\||_{2} ds = \\langle  -\\nabla f(x), d \\rangle + \\frac{L}{2} \\||d\\||_{2}^2\\\\\n",
    "=- \\langle  \\nabla f(x), d \\rangle + \\frac{L}{2} \\||d\\||_{2}^2 \\\\\n",
    "\\implies f(x - d) \\leq f(x) - \\langle  \\nabla f(x), d \\rangle + \\frac{L}{2} \\||d\\||_{2}^2\n",
    "\\end{align*}\n",
    "\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimise we set the gradient to 0 wrt. d:\n",
    "$\\nabla_d (f(x) - \\langle \\nabla f(x), d \\rangle + \\frac{L}{2} ||d||^2) = 0 \\\\ $\n",
    "$\\implies - \\nabla f(x) + L d = 0 \\implies d = \\frac{1}{L} \\nabla f(x)$\n",
    "We know this is a minimise since since the second derivating wrt. d is $L*I$ which is positive definite as $L > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can formulate two inequalities from:<br>\n",
    "    1. f is convex and differentiable everywhere: $f(x) \\geq f(\\bar{x}) + \\langle \\nabla f(\\bar{x}), x - \\bar{x} \\rangle$<br>\n",
    "    2. the equation from part 1: $f(\\hat{x}) \\leq f(\\bar{x}) - \\langle \\nabla f(\\bar{x}), \\bar{d} \\rangle + \\frac{L}{2} ||\\bar{d}||^2$.<br>\n",
    "\n",
    "reversing the second inequality and adding it to the first inequality, we get:\n",
    "$$\n",
    "f(x) - f(\\hat{x}) \\geq \\langle \\nabla f(\\bar{x}), x - \\bar{x} \\rangle - \\langle \\nabla f(\\bar{x}), \\bar{d} \\rangle + \\frac{L}{2} ||\\bar{d}||^2 \\\\ \n",
    "= \\langle \\nabla f(\\bar{x}), x - \\hat{x} \\rangle - \\frac{L}{2} ||\\bar{d}||^2\n",
    "$$\n",
    "Where we used that $L \\bar{d} = \\nabla f(x) $ in the last step.<br><br>\n",
    "We must keep in mind that $\\bar{d} = \\bar{x} - \\hat{x}$<br>\n",
    "Substituting this in, we have:\n",
    "$$\n",
    "\\text{We use that $\\nabla f(x) = L (\\bar{x}- \\hat{x})$ here} \\\\\n",
    "\\begin{align*}\n",
    "f(x) - f(\\hat{x}) \\geq L \\langle \\bar{x} - \\hat{x}, x - \\bar{x} \\rangle + \\frac{L}{2} ||\\bar{x} - \\hat{x}||^2_2 \\\\\n",
    "= \\frac{L}{2} (2 \\langle \\bar{x} - \\hat{x}, x - \\bar{x} \\rangle \n",
    "+ \\langle \\bar{x} - \\hat{x},\\bar{x} - \\hat{x} \\rangle\n",
    "+ \\langle x - \\bar{x}, x - \\bar{x} \\rangle - \\langle x - \\bar{x}, x - \\bar{x} \\rangle) \\\\\n",
    "= \\frac{L}{2} ( \\langle \\bar{x} - \\hat{x} + x - \\bar{x}, \\bar{x} - \\hat{x} + x - \\bar{x} \\rangle \n",
    "- \\langle x - \\bar{x}, x - \\bar{x} \\rangle) \\\\\n",
    "= \\frac{L}{2} ( ||x - \\hat{x}||^2 - ||x - \\bar{x}||^2) \\\\ \n",
    "f(x) - f(\\hat{x}) \\geq \\frac{L}{2} ( ||x - \\hat{x}||^2 - ||x - \\bar{x}||^2) \\\\ \\implies  f(x) + \\frac{L}{2} ||x - \\bar{x}||^2 \\geq f(\\hat{x}) + \\frac{L}{2} ||x - \\hat{x}||^2\n",
    "\\end{align*}\n",
    "$$\n",
    "Note that we used the identity $||a+b||^2  = 2 \\langle a, b \\rangle + ||a||^2 + ||b||^2$ in the third step. by setting a = $\\bar{x} - \\hat{x}$ and b = $x - \\bar{x}$ so that $a + b = x - \\hat{x}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prove by induction\n",
    "Base Case: For k = 1\n",
    "$$\n",
    "t_1 = \\frac{1 + \\sqrt{1 + 4 t_0^2}}{2} = \\frac{1 + \\sqrt{1 + 0}}{2} = 1 \\geq 1 = 1 + 1 / 2\n",
    "$$\n",
    "Assume true for some k i.e $ t_{k} \\geq \\frac{k+1}{2}$\n",
    "$$\n",
    "t_{k+1} = \\frac{1 + \\sqrt{1 + 4 t_k^2}}{2} \\geq \\frac{1 + \\sqrt{1 + 4 \\frac{(k+1)^2}{4}}}{2} = \\\\ \\frac{1 + \\sqrt{(k+1)^2 + 1}}{2} \\geq \\frac{1 + \\sqrt{(k+1)^2}}{2} = \\frac{(k+1) + 1}{2} = \\frac{k+2}{2}\n",
    "$$ \n",
    "\n",
    "\n",
    "Hence, by induction, the statement holds for all k >= 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will show that $||t_{k+1}(x - \\bar{x}_k) ||^2_2 = ||u_k - x^*||^2_2$\n",
    "$$\n",
    "t_{k+1}(x - \\bar{x}_k) = \\frac{t_{k+1}}{t_{k+1}}((t_{k+1}-1)x_k +x^*) - t_{k+1}(x_k + \\frac{t_k - 1}{t_{k+1}}(x_k - x_{k-1}))\\\\\n",
    "= t_{k+1}x_k-x_k +x^* - (t_{k+1}x_k + t_k(x_k - x_{k-1}) -x_k + x_{k-1})\\\\\n",
    "= t_{k+1}x_k - x_k +x^* - t_{k+1}x_k - t_k(x_k - x_{k-1})  + x_k - x_{k-1}\\\\\n",
    "= - (t_k(x_k-x_{k-1}) - (x_k - x^*)) = u_k - x^*\n",
    "$$\n",
    "Hence, $||t_{k+1}(x - x) ||^2_2 = ||u_k - x^*||^2_2$\n",
    "\n",
    "Now we will show that $t_{k+1}||x-x_{k+1}||^2_2 = ||u_{k+1} -x^*||^2_2$\n",
    "$$\n",
    "    t_{k+1}(x - x_{k+1}) = t_{k+1}x_k - x_k + x^* - t_{k+1}x_{k+1}\\\\\n",
    "    = -( x_k + t_{k+1}(x_{k+1} -x_k) - x^*) = -(u_{k+1} - x^*)\n",
    "\n",
    "$$\n",
    "Hence, $t_{k+1}||x-x_{k+1}||^2_2 = ||u_{k+1} -x^*||^2_2$\n",
    "Thus, \n",
    "$$\n",
    "t_{k+1}^2(||(x - \\bar{x}_k) ||^2_2 - ||x - x_{k+1}||^2_2) = ||u_k - x^*||^2_2 - ||u_{k+1} -x^*||^2_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from convexity of f, we have \n",
    "$$f(x) = f(\\frac{t_{k+1} - 1}{t_{k+1}}x_k + \\frac{1}{t_{k+1}}x^*) \\leq \\frac{t_{k+1} - 1}{t_{k+1}}f(x_k) + \\frac{1}{t_{k+1}}f(x^*)$$\n",
    "where $x = \\frac{t_{k+1} - 1}{t_{k+1}}x_k + \\frac{1}{t_{k+1}}x^*$<br>\n",
    "From 2.3, we have: \n",
    "$$ f(x) + \\frac{L}{2} ||x - \\bar{x_k}||^2 \\geq f(\\hat{x}) + \\frac{L}{2} ||x - \\hat{x}||^2 \\\\ \n",
    "\\implies f(\\hat{x}) - \\frac{L}{2} ( ||x - \\bar{x_k}||^2 - ||x - \\hat{x}||^2) \\leq f(x)\n",
    "$$\n",
    "Combining these two inequalities, we have:\n",
    "$$ f(\\hat{x}) - \\frac{L}{2} ( ||x - \\bar{x_k}||^2 - ||x - \\hat{x}||^2) \\leq\\frac{t_{k+1} - 1}{t_{k+1}}f(x_k) + \\frac{1}{t_{k+1}}f(x^*)\\\\ \n",
    "\\implies t_{k+1}^2 (f(\\hat{x}) - f(x^*)) -  \\frac{L}{2}(||u_k - x^*||^2_2 - ||u_{k+1} -x^*||^2_2) \\leq t_{k+1}(t_{k+1} - 1)(f(x_k) - f(x^*)) \\\\\n",
    "\\implies t_{k+1}^2(f(\\hat{x}) - f(x^*)) - \\frac{L}{2}(||u_k - x^*||^2_2 - ||u_{k+1} -x^*||^2_2) \\leq t_{k}^2(f(x_k) - f(x^*))\n",
    "$$\n",
    "setting f(\\hat{x}) = f(x_{k+1}) we get:\n",
    "$$ t_{k+1}^2(f(x_{k+1}) - f(x^*)) - \\frac{L}{2}(||u_k - x^*||^2_2 - ||u_{k+1} -x^*||^2_2) \\leq t_{k}^2(f(x_k) - f(x^*)) \\\\ \n",
    "\\implies t_{k+1}^2(f(x_{k+1}) - f(x^*)) + \\frac{L}{2}||u_{k+1} -x^*||^2_2 \\leq t_{k}^2(f(x_k) - f(x^*)) + \\frac{L}{2}||u_k - x^*||^2_2\n",
    "$$\n",
    "Inductively, we see that:\n",
    "$$\n",
    "t_{k+1}^2(f(x_{k+1}) - f(x^*)) + \\frac{L}{2}||u_{k+1} -x^*||^2_2 \\leq t_{k}^2(f(x_k) - f(x^*)) + \\frac{L}{2}||u_k - x^*||^2_2 \\leq ... \\leq t_0^2(f(x_0) - f(x^*)) + \\frac{L}{2}||u_0 - x^*||^2_2\n",
    "$$\n",
    "$t_0 = 0, u_0 = x_{-1} + t_0(x_0 - x_{-1}) = x_{-1} = x_0$, hence:\n",
    "$$t_{k}^2(f(x_k) - f(x^*)) \\leq t_{k}^2(f(x_k) - f(x^*)) + \\frac{L}{2}||u_k - x^*||^2_2 \\leq \\frac{L}{2}||x_0 - x^*||^2_2 \\\\\n",
    "\\implies f(x_k) - f(x^*) \\leq \\frac{L||x_0 - x^*||^2_2}{2t_k^2}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Exercise 3: [15 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14447, 8]) torch.Size([14447, 1])\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Train-validation-test split\n",
    "num_samples = X_tensor.shape[0]\n",
    "train_size = int(0.7 * num_samples)\n",
    "val_size = int(0.15 * num_samples)\n",
    "test_size = num_samples - train_size - val_size\n",
    "\n",
    "X_train = X_tensor[:train_size]\n",
    "y_train = y_tensor[:train_size]\n",
    "X_val = X_tensor[train_size:train_size + val_size]\n",
    "y_val = y_tensor[train_size:train_size + val_size]\n",
    "X_test = X_tensor[train_size + val_size:]\n",
    "y_test = y_tensor[train_size + val_size:]\n",
    "print(X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have designed a neural network that has an input layer, n hidden lauers and an output layer. When doing the forward pass, each layer applies a linear transformation followed by a activation function step except for the output layer. \n",
    "\n",
    "We used nn.ModuleList so that we can have a variable number of hidden layers n. <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNetwork(nn.Module):\n",
    "    # TODO fill in the arguments\n",
    "    def __init__(self, act_func,input_size, output_size, hidden_sizes):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            act_fn - Object of the activation function that should be used as non-linearity in the network.\n",
    "            input_size - Size of the input images in pixels\n",
    "            output_size - Number of classes we want to predict\n",
    "            hidden_sizes - A list of integers specifying the hidden layer sizes in the NN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO Define and initialize layers here\n",
    "        layers = []\n",
    "        input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        layers.append(input_layer)\n",
    "        layers.append(act_func)\n",
    "        self.act_func = act_func\n",
    "\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            hidden_layer = nn.Linear(hidden_sizes[i], hidden_sizes[i + 1])\n",
    "            layers.append(hidden_layer)\n",
    "            layers.append(act_func)\n",
    "        output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "        # self.act_func = act_func\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.output_layer = output_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Implement the forward pass\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        out = x\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the network, allows us to see the sizes of alll the layers. The output layer is separated from the ModuleList since it is not followed by an activation function. We have copies of the relu function after every hidden layer. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseNetwork(\n",
      "  (act_func): ReLU()\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=8, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (output_layer): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = BaseNetwork(nn.ReLU(), X_train.shape[1],y_train.shape[1],[32,16,8])\n",
    "print(network)\n",
    "\n",
    "# ANSWER TO QUESTION 2:\n",
    "# for p in network.parameters():\n",
    "#     print(p.shape)\n",
    "#     print(p.grad)\n",
    "\n",
    "# parameters() is an inbuilt function in PyTorch nn.module class that returns a list of all Tensor parameters of the module.\n",
    "# It outputs the shape and gradient of each parameter in the network. The grad will be none because we haven't performed any bacpropagation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using torch's mse loss function we comput e the mean squared error between the predicted output and the true output. in myLoss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "     \n",
    "    def __init__(self, mynet, X, y, learning_rate, tolerance=1e-6):\n",
    "        '''\n",
    "        Initializes the Optimizer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mynet : nn.Module\n",
    "            The neural network model to be optimized.\n",
    "        X : 2D torch Tensor\n",
    "            Input data with dimensions (n_samples, n_features).\n",
    "        y : 1D torch Tensor\n",
    "            Output/target data with dimension (n_samples,).\n",
    "        learning_rate : float\n",
    "            Learning rate or regularization parameter.\n",
    "        tolerance : float, optional\n",
    "            Tolerance for convergence criteria.\n",
    "        '''\n",
    "\n",
    "        # Storing initial data\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        # Extracting dimensions\n",
    "        self.n_sample, self.n_feature = X.shape\n",
    "\n",
    "        self.net = mynet\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "\n",
    "        # Algorithm history\n",
    "        self.obj_history = []\n",
    "\n",
    "    # TODO: implement myloss method\n",
    "    def myLoss(self, X, y):\n",
    "        out = self.net(X)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        loss = loss_fn(out, y)\n",
    "        return loss\n",
    "    \n",
    "    def plot_loss(self):\n",
    "\n",
    "        if len(self.obj_history) == 1:\n",
    "            raise ValueError('No history to plot.')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.plot(self.obj_history, color='k')\n",
    "        ax.set_ylabel('Objective Function Value')\n",
    "        ax.set_xlabel('Iteration')\n",
    "        ax.grid()\n",
    "        fig.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent optimiser repeatedly updates the weights of the network based on how well the loss function is minimised. We use a constant learning rate when updating the weights. We also make use of an obj_history to track the loss at each iteration so that we can plot it later\n",
    "\n",
    " We tend to finish all iterations without hitting the tolerance threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescentOptimiser(Optimizer):\n",
    "    def __init__(self, mynet, X, y, learning_rate, tolerance=1e-6):\n",
    "        super().__init__(mynet, X, y, learning_rate, tolerance)\n",
    "\n",
    "        self.algorithm_name = 'Gradient Descent'\n",
    "\n",
    "    def run(self, max_iter=10000):\n",
    "\n",
    "        for it in range (max_iter):\n",
    "            # print(self.obj_history)\n",
    "            self.net.zero_grad()\n",
    "\n",
    "            loss = self.myLoss(self.X, self.y)\n",
    "            loss.backward()\n",
    "            self.obj_history.append(loss.item())\n",
    "            # print(self.obj_history)\n",
    "# \n",
    "\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                for param in self.net.parameters():\n",
    "                    # print(param.grad)\n",
    "                    param -= self.learning_rate * param.grad\n",
    "            if len(self.obj_history) > 1 and abs(self.obj_history[-2] - self.obj_history[-1]) < self.tolerance:\n",
    "                break\n",
    "        print(\"abs(self.obj_history[-2] - self.obj_history[-1]):\", abs(self.obj_history[-2] - self.obj_history[-1]))\n",
    "        print(\"Finished at iteration:\", it)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run our optimiser for 100 iterations and then plot the loss with our network, that initially uses RELU as the activation function. \n",
    "SELU gives us the lowest final loss value. \n",
    "Equation of SELU:\n",
    "$$\n",
    "selu(x) = \\lambda \\begin{cases} x & \\text{if } x > 0 \\\\ \\alpha e^{x} - \\alpha & \\text{if } x \\leq   0 \\end{cases}\n",
    "$$\n",
    "\n",
    "The benefit of selu is that we can be sure that the output is standardised as it is self normalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs(self.obj_history[-2] - self.obj_history[-1]): 4.604458808898926e-05\n",
      "Finished at iteration: 999\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set: 0.8864074945449829\n",
      "-------------------------\n",
      "Activation Function: Tanh()\n",
      "abs(self.obj_history[-2] - self.obj_history[-1]): 0.0002480149269104004\n",
      "Finished at iteration: 999\n",
      "validation set: 1.4088994264602661\n",
      "-------------------------\n",
      "-------------------------\n",
      "Activation Function: Sigmoid()\n",
      "abs(self.obj_history[-2] - self.obj_history[-1]): 9.5367431640625e-07\n",
      "Finished at iteration: 854\n",
      "validation set: 1.7096019983291626\n",
      "-------------------------\n",
      "-------------------------\n",
      "Activation Function: LeakyReLU(negative_slope=0.01)\n",
      "abs(self.obj_history[-2] - self.obj_history[-1]): 0.00020253658294677734\n",
      "Finished at iteration: 999\n",
      "validation set: 1.6873700618743896\n",
      "-------------------------\n",
      "-------------------------\n",
      "Activation Function: ELU(alpha=1.0)\n",
      "abs(self.obj_history[-2] - self.obj_history[-1]): 0.00012308359146118164\n",
      "Finished at iteration: 999\n",
      "validation set: 1.16725492477417\n",
      "-------------------------\n",
      "-------------------------\n",
      "Activation Function: SELU()\n",
      "abs(self.obj_history[-2] - self.obj_history[-1]): 5.435943603515625e-05\n",
      "Finished at iteration: 999\n",
      "validation set: 0.8821450471878052\n",
      "-------------------------\n",
      "Activation Function: SELU(), Validation Loss: 0.8864074945449829\n",
      "Activation Function: Tanh(), Validation Loss: 1.4088994264602661\n",
      "Activation Function: Sigmoid(), Validation Loss: 1.7096019983291626\n",
      "Activation Function: LeakyReLU(negative_slope=0.01), Validation Loss: 1.6873700618743896\n",
      "Activation Function: ELU(alpha=1.0), Validation Loss: 1.16725492477417\n",
      "Activation Function: SELU(), Validation Loss: 0.8821450471878052\n"
     ]
    }
   ],
   "source": [
    "#Training and optimising\n",
    "learning_rate = 0.001\n",
    "gd_optimizer = GradientDescentOptimiser(network, X_train, y_train, learning_rate=learning_rate)\n",
    "gd_optimizer.run(max_iter=1000)\n",
    "\n",
    "# plotting training\n",
    "gd_optimizer.plot_loss()\n",
    "\n",
    "# computing loss over validation set\n",
    "val_loss = gd_optimizer.myLoss(X_val, y_val)\n",
    "print(f'validation set: {val_loss.item()}')\n",
    "\n",
    "# test with different activation function\n",
    "losses = {}\n",
    "losses[network.act_func] = val_loss.item()\n",
    "act_funcs = [nn.Tanh(), nn.Sigmoid(), nn.LeakyReLU(), nn.ELU(), nn.SELU()]\n",
    "for act in act_funcs:\n",
    "    print('-------------------------')\n",
    "    network = BaseNetwork(act, X_train.shape[1],y_train.shape[1],[32,16,8])\n",
    "    print(f'Activation Function: {act}')\n",
    "    # network.act_func = act\n",
    "    gd_optimizer = GradientDescentOptimiser(network, X_train, y_train, learning_rate=0.001)\n",
    "    gd_optimizer.run(max_iter=1000)\n",
    "    # gd_optimizer.plot_loss()\n",
    "    val_loss = gd_optimizer.myLoss(X_val, y_val)\n",
    "    losses[act] = val_loss.item()\n",
    "    print(f'validation set: {val_loss.item()}')\n",
    "    print('-------------------------')\n",
    "\n",
    "for act, loss in losses.items():\n",
    "    print(f'Activation Function: {act}, Validation Loss: {loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt(x):\n",
    "    return x ** 0.5\n",
    "\n",
    "class AcceleratedGradient(Optimizer):\n",
    "    def __init__(self, mynet, X, y, learning_rate, tolerance=1e-6):\n",
    "        super().__init__(mynet, X, y, learning_rate, tolerance)\n",
    "   \n",
    "    def run(self, max_iters=1000):\n",
    "        '''\n",
    "        Runs the optimization algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_iters : int, optional\n",
    "            Maximum number of iterations to run the algorithm. The default is 1000.\n",
    "        '''\n",
    "        t_old = 0\n",
    "        x_old = [p.clone() for p in self.net.parameters()]\n",
    "        for i in range (1, max_iters + 1):\n",
    "\n",
    "            t_new = (1 + sqrt(1 + 4*(t_old**2)))/2\n",
    "            for j, p in enumerate(self.net.parameters()):\n",
    "                x_cur = p.data.clone()\n",
    "                x_bar_cur = x_cur + ((t_old - 1)/t_new) * (x_cur - x_old[j])\n",
    "                x_old[j] = x_cur\n",
    "                p.data = x_bar_cur\n",
    "\n",
    "            #  [x_c + ((t_old - 1)/t_new) * (x_c - x_o) for x_c, x_o in zip(x_cur, x_old)]\n",
    "\n",
    "            self.net.zero_grad()\n",
    "            loss = self.myLoss(self.X, self.y)\n",
    "            loss.backward()\n",
    "            self.obj_history.append(loss.item())\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for param in self.net.parameters():\n",
    "                    param.data -= self.learning_rate * param.grad\n",
    "            if len(self.obj_history) > 1 and abs(self.obj_history[-2] - self.obj_history[-1]) < self.tolerance:\n",
    "                break\n",
    "            t_old = t_new\n",
    "\n",
    "        # TODO: Implement the accelerated gradient steps here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new Accelerated Gradient optimiser we can see that the loss decreases much faster than with standard gradient descent. Within the first 100 itereations, we can see that the loss has decreased to a very small value. \n",
    "\n",
    "Comparing this to standard gradient descent, we can see that the loss is still quite high even after 500 iterations. The previous gradient descent method was about 4 times higher in lost going from 1.0 to 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss with Accelerated Gradient: 0.2730548083782196\n"
     ]
    }
   ],
   "source": [
    "new_network = BaseNetwork(nn.SELU(), X_train.shape[1],y_train.shape[1],[32,16,8])\n",
    "\n",
    "accelerated_optimizer = AcceleratedGradient(new_network, X_train, y_train, learning_rate=0.001)\n",
    "accelerated_optimizer.run(max_iters=1000)\n",
    "accelerated_optimizer.plot_loss()\n",
    "print(\"Final loss with Accelerated Gradient:\", accelerated_optimizer.obj_history[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
